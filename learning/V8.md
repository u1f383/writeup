### Build environment

工具

- `depot_tools` - Chromium 和 Chromium OS 用來管理 checkout 以及 code review 的腳本 package

  - [man](http://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/depot_tools_tutorial.html)

  - ```
    git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git
    echo "export PATH=/path_to_depot_tools:$PATH" >> ~/.zshrc
    ```

- `ninja` - a build system focus on speed

- `gclient` - 管理 subversion 以及 checkout 的工具，並且同時能跑在多個平台 + 支援 svn 與 git

### Build v8

[文件](https://chromium.googlesource.com/external/github.com/v8/v8.wiki/+/8c0be5e888bda68437f15e2ea9e317fd6229a5e3/Building-with-GN.md)

```bash
fetch v8 # 使用 depot_tools 提供的腳本下載 v8 repo + third party
cd v8 && gclient sync && ./build/install-build-deps.sh # 安裝相依套件

# build release version
tools/dev/v8gen.py x64.release
ninja -C out.gn/x64.release

# build optional debug version
tools/dev/v8gen.py x64.optdebug
ninja -C out.gn/x64.optdebug

# build debug version
tools/dev/v8gen.py x64.debug
ninja -C out.gn/x64.debug
```

- `d8` - v8’s own **developer shell**
- `gm` - all-in-one script
-  `v8gen.py` - convenience script to generate your build files

### d8

```bash
# trace optimization with verbose
./d8 --trace-opt-verbose test.js

# trace optimization + deoptimization
./d8 --trace-opt --trace-deopt test.js

# trace TurboFan inlining
./d8 --trace-turbo-inlining test.js

# trace trace generated TurboFan IR
./d8 --trace-turbo test.js

# trace garbage collection
./d8 --trace-gc test.js

# 允許使用 RUNTIME function (% as prefix)，像是 %DebugPrint()
./d8 --allow-natives-syntax test.js
```

### Runtime function cheatsheet

[runtime.h](https://source.chromium.org/chromium/chromium/src/+/main:v8/src/runtime/runtime.h;l=6?q=runtime.h&sq=)

```bash
# disasm 指定的 function
%DisassembleFunction();

# show var info
%DebugPrint(var);

# show pointer info 
%DebugPrintPtr(ptr);

# int3 bp
%SystemBreak();
```

### Turbolizer

可以產生視覺化的 graph 藉此分析 TurboFan 行為的 tool

```bash
# In v8 directory
cd tools/turbolizer
npm i
npm run-script build
python -m SimpleHTTPServer
```



Render

- [Life of a Pixel](https://docs.google.com/presentation/d/1boPxbgNrTU0ddsc144rcXayGA_WF53k96imRH8Mp34Y/edit#slide=id.ga884fe665f_64_6)
- [How blink works](bit.ly/lifeofapixel)



**Sandbox**

- 在 Linux 上分成兩個等級:

  1. Semantics layer - prevents access to most resources from a process where it's engaged
     - **setuid sandbox**
     - disable by `--disable-setuid-sandbox`
  2. Attack surface reduction layer - 用 kernel feature 限制攻擊範圍
     -  **Seccomp-BPF** (sandbox/linux/seccomp-bpf/sandbox_bpf.cc)
     - disable by `--disable-seccomp-filter-sandbox`
  3. disable all sandbox by `--no-sandbox`



### TurboFan

- `deoptimization` (或被稱作 `bailout`) - 由於程式因為傳入參數或是其他關係，導致執行流程跟先前不同，優化過的程式碼變得無法使用，因此必須移除掉舊的 bytecode (or machine code)
- `TurboFan` 使用 **sea of nodes** 來表示一個 program
  - node 代表 arithmetic op、load、store、call、constant 等等
  - edge 有三種:
    - control edge - find in CFG, branches and loops
    - value edge - find in DFG, value dependencies
    - effect edge - order operations such as reading or writing states



### GC

GC judges pointers and non-pointers

- Accurate GC - pointer tagging

  - Tag bits

    - signal either strong/weak pointers to objects located in V8 heap, or a small integer

    - the value of an integer can be stored directly in the tagged value, without having to allocate additional storage for it

    - ```
          				|----- 32 bits -----|----- 32 bits -----|
      Pointer:    |________base_______|______offset_____w1|
      Smi:        |sssssssssssssssssss|____int31_value___0|
      
                          |----- 32 bits -----|----- 32 bits -----|
      Compressed pointer:                     |______offset_____w1|
      Compressed Smi:                         |____int31_value___0|
      ```

      - `w` is a bit used for distinguishing strong pointers from the weak ones
      - `s` is the sign value of the Smi payload
      - V8 always allocates objects in the heap at `word-aligned` (4 bytes, `address % 4 == 0`) addresses

    - Decompress

      - v1 (base 0)

        ```c
        uint32_t compressed_tagged;
        
        uint64_t uncompressed_tagged;
        if (compressed_tagged & 1) {
          // pointer case
          uncompressed_tagged = base + uint64_t(compressed_tagged);
        } else {
          // Smi case
          uncompressed_tagged = int64_t(compressed_tagged);
        }
        ```

        - need to distinguish between **sign-extending the Smi** and **zero-extending the pointer**

      - v2 (put the base in the middle (2GB))

        ```c
        int32_t compressed_tagged;
        
        // Same code for both pointer and Smi cases
        int64_t sign_extended_tagged = int64_t(compressed_tagged);
        int64_t selector_mask = -(sign_extended_tagged & 1);
        // Mask is 0 in case of Smi or all 1s in case of pointer
        int64_t uncompressed_tagged =
            sign_extended_tagged + (base & selector_mask);
        ```




### V8 Torque

一種程式語言讓開發人員可以更好的呈現程式碼的改變，可以花更多時間在開發，而不是花時間在不相關的資料

- **TypeScript** - like syntax that eases both writing and understanding V8 code with syntax and types that reflects concepts that are already common in the **CodeStubAssembler**
- 在 `src/builtins` 有許多 `.tq` 為副檔名的檔案
- `torque` compiler 在 `src/torque`



---

### PartitionAlloc

**PartitionAlloc** 為 Chromium 所使用的 memory allocator，設計目標為 lower fragmentation, higher speed, and stronger security，已經在 Blink 廣泛使用 (Chromium’s rendering engine)

In **Chrome 89** the entire Chromium codebase transitioned to using **PartitionAlloc everywhere** (by **intercepting and replacing malloc() and new**) on Windows 64-bit and Android

- 在這兩個作業系統上已經完全用 PA 取代原本的記憶體分配機制



**PartitionAlloc-Everywhere**

- 一開始 PA 只用在 **Blink** (Chromium’s rendering engine)，並透過 call PartitionAlloc APIs 使用
- PartitionAlloc-Everywhere is the name of the project that brought PartitionAlloc to the **entire-ish codebase** (exclusions apply)
  - 主要實作是透過 intercepting malloc(), free(), realloc(), aforementioned posix_memalign() 等等記憶體分配相關的 function，並且轉而呼叫 PA
- The shim located in `base/allocator/allocator_shim_default_dispatch_to_partition_alloc.h` is responsible for intercepting
- A special, **catch-it-all Malloc partition** has been created for the **intercepted malloc()** et al. This is to **isolate from already existing Blink partitions**. The only exception from that is Blink‘s FastMalloc partition, which was also catch-it-all in nature, so it’s perfectly fine to merge these together, to **minimize fragmentation**
- 已經實踐於：
  - M89 for Windows 64-bit and Android
  - Windows 32-bit and Linux followed it shortly after, in M90



PA 的相關名詞：

- slot - indivisible allocation unit
  - 因為 slot 需要 per-partition lock，因此會需要 per-thread cache TLS 來增加速度

- slot span - groups slots of the same size into well-packed, multi-page regions
- bucket - chains slot spans containing slots of the same size (3 lists, by availability)
- super page - pre-reserved 2MiB address space slab, home for **slot spans** & **metadata** describing them
- partition - groups super pages
- 一旦分配的 address region (<= 960KB allocation) 屬於某個 partition/slot span，就會一直在那



Central allocator lock per partition：

- common solution: multiple partitions / arenas -> More memory
- approach: simplest, smallest solution with decent performance
  - small, lock-free, **per-thread cache of free slots (ready to allocate by thread)**
  - thread cache
- per-thread cache
  - performanace critical
  - 不用 lock --> 沒有 contention
  - 當用完的時候在從 lock 的地方要一個大的記憶體區塊繼續切



**Slab allocation**

- a memory management mechanism intended for the efficient memory allocation of objects
- reduces **fragmentation** caused by allocations and deallocations
- cache
  - cache represents a **small amount of very fast memory**
  - a cache is a storage for a **specific type of object**, such as **semaphores**, **process descriptors**, **file objects**, etc.
- slab
  - slab represents a **contiguous piece of memory**, usually made of **several physically contiguous pages**
  - The slab is the actual **container of data** associated with objects of the **specific kind of the containing cache**
- When a program sets up a cache, it allocates a **number of objects to the slabs** associated with that **cache**
- This number depends on **the size of the associated slabs**
- Slabs may exist in one of the following states :
  - empty – all objects on a slab marked as **free**
  - partial – slab consists of **both used and free objects**
  - full – all objects on a slab marked as **used**



**PartitionAlloc 細節**

- pre-reserves slabs of virtual address space
- **Small** and **medium**-sized allocations are grouped in geometrically-spaced, **size-segregated buckets**
  - e.g. [241; 256], [257; 288]

- Each slab is split into regions (called “**slot spans**”) that satisfy allocations (“**slots**”) from only one particular bucket, thereby increasing **cache locality** while **lowering fragmentation**
- Conversely, larger allocations don’t go through the bucket logic and are fulfilled **using the operating system’s primitives directly**
- **central allocator** is protected by a single **per-partition lock**
- To mitigate the scalability problem arising from contention, we add a small, **per-thread cache** of **small slots** in front, yielding a three-tiered (三層) architecture
  - **first layer (Per-thread cache)** - holds **a small amount of slots** belonging to smaller and more commonly used **buckets**
    - Because these slots are stored **per-thread**, they can be allocated **without a lock** and only requiring a faster **thread-local storage** (TLS) lookup, improving **cache locality** in the process. The per-thread cache has been tailored to satisfy the majority of requests by allocating from and releasing memory to the second layer in **batches**, amortizing lock acquisition, and further improving locality while not trapping excess memory
  - **second layer (Slot span free-lists)** - is invoked upon a **per-thread cache miss**. For each bucket size, PartitionAlloc knows a **slot span** with **free slots** associated with that **size**, and captures a slot from the **free-list of that span**. This is still a **fast path**, but slower than per-thread cache as it requires taking a lock
    - However, this section is only hit for larger allocations not supported by per-thread cache, or as **a batch to fill the per-thread cache.**
  - Finally, if there are **no free slots in the bucket**, the third layer (Slot span management) either carves out space from a slab for a new slot span, or allocates an **entirely new slab from the operating system**, which is a slow but very infrequent operation



A **partition** is a heap that is **separated and protected from any other partitions**

- to isolate certain object types
  - isolate objects of **certain sizes** or objects of a **certain lifetime**
- Each partition holds multiple **buckets**



A **bucket** is a series of regions in a partition that contains **similar-sized objects**, e.g. one bucket holds sizes (240, 256], another (256, 288], and so on

- `kMaxBucketed=960KiB` (so called normal buckets)
- 8 buckets between each power of two
- Larger allocations (`>kMaxBucketed`) are realized by direct memory mapping (**direct map**).



**PartitionAlloc** is designed to be extremely fast in its **fast paths**. The fast paths of allocation and deallocation require **very few (reasonably predictable) branches**. The number of operations in the fast paths is **minimal**, leading to the possibility of **inlining**.

- even the fast path **isn't the fastest**, because it requires taking a **per-partition lock**
- Therefore we introduced the **thread cache**, which holds **a small amount of not-too-large memory chunks**, **ready to be allocated**
- Because these chunks are stored **per-thread**, they can be allocated **without a lock**, only requiring a faster **thread-local storage (TLS)** lookup, improving **cache locality** in the process
- The thread cache has been tailored to satisfy a vast majority of requests by allocating from and releasing memory to the main allocator in batches, amortizing lock acquisition and further improving locality while not trapping excess memory



PartitionAlloc guarantees that **different partitions exist in different regions** of the process's address space. When the caller has freed **all objects contained in a page in a partition**, PartitionAlloc returns the physical memory to the operating system, but continues to **reserve the region of address space**. PartitionAlloc will only **reuse an address space region for the same partition**.

Similarly, one page can contain only objects from the **same bucket**. When freed, PartitionAlloc returns the physical memory, but continues to reserve the region for **this very bucket**.

- partition 會被 PartitionAlloc 分在不同的 region，並且當 partition 內的空間都沒在使用時，PartitionAlloc 會釋放物理空間，並且保留這塊虛擬記憶體區塊作為下次使用
- page 也相同，當內部的 bucket 都沒在使用，釋放物理空間並保留虛擬記憶體區塊



The above techniques help **avoid type confusion attacks**. Note, however, these apply **only to normal buckets** and not to direct map, as it'd waste too much address space.

PartitionAlloc also guarantees that:

- **Linear overflows/underflows** cannot corrupt into, out of, or **between partitions**. There are **guard pages** at the beginning and the end of each memory region owned by a partition.
- Linear overflows/underflows **cannot corrupt the allocation metadata**. PartitionAlloc records **metadata** in a dedicated, **out-of-line region** (not adjacent to objects), **surrounded by guard pages**. (**Freelist pointers are an exception**.)
  - partition 的 metadata 存在不同地方，並且周遭會有 guard page，因此避免了 overflow

- **Partial pointer overwrite of freelist pointer should fault**.
- Direct map allocations have **guard pages** at **the beginning and the end**.



PartitionAlloc guarantees that returned pointers are aligned on `base::kAlignment` boundary (typically **16B** on 64-bit systems, and **8B** on 32-bit).

PartitionAlloc also supports higher levels of alignment, that can be requested via `PartitionAlloc::AlignedAllocFlags()` or platform-specific APIs (such as `posix_memalign()`)

The requested alignment has to **be a power of two**. PartitionAlloc reserves the right to **round up the requested size** to the **nearest power of two**, greater than or equal to the requested alignment. This may be wasteful, but allows taking advantage of natural PartitionAlloc alignment guarantees. Allocations with an alignment requirement greater than `base::kAlignment` are expected to be very rare.



In PartitionAlloc, by system page we mean a memory page as defined by **CPU/OS (often referred to as “virtual page” out there)**. It is most commonly **4KiB** in size, but depending on CPU it can be larger (PartitionAlloc supports up to **64KiB**).

The reason why we use the term “system page” is to disambiguate from partition page, which is the most common granularity used by PartitionAlloc. Each partition page consists of exactly **4 system pages.**

- 一個 partition page 包含 4 個 system page，也就是 0x4000



A **super page** is a **2MiB** region, aligned on a 2MiB boundary. Don't confuse it with CPU/OS terms like “**large page**” or “**huge page**”, which are also **commonly 2MiB in size**. These have to be fully committed/uncommitted in memory, whereas super pages can be partially committed, with system page granularity.

- super page 為 2MB 大小的區塊



A slot is an **indivisible allocation unit**. **Slot sizes are tied to buckets**. For example each allocation that falls into the bucket (240; 256] would be satisfied with a slot of size 256. This applies only to **normal buckets**, not to **direct map**.

A **slot span** is just a grouping of slots of the **same size** next to each other in memory. Slot span size is a multiple of a partition page.

A **bucket is a collection of slot spans** containing slots of the same size, organized as linked-lists.



Allocations up to 4 partition pages are referred to as small buckets

- In these cases, **slot spans** are always between **1 and 4 partition pages in size.**
- The size is chosen based on the **slot size**, such that the rounding waste is minimized
  - 大小會根據 slot size 有所不同

- For example, if the **slot size was 96B** and slot span was 1 partition page of 16KiB, 64B would be wasted at the end, but nothing is wasted if 3 partition pages totalling 48KiB are used
- Furthermore, PartitionAlloc may **avoid waste by lowering the number of committed system pages** compared to the number of reserved pages
  - For example, for the slot size of 80B we'd use a slot span of 4 partition pages of 16KiB, i.e. 16 system pages of 4KiB, but commit only up to 15, thus resulting in perfect packing.




Allocations above 4 partition pages (but `≤kMaxBucketed`) are referred to as **single slot spans**. That‘s because each slot span is guaranteed to hold exactly **one slot**

Fun fact: there are sizes `≤4 partition pages` that result in a **slot span having exactly 1 slot**, but nonetheless they’re still classified as **small buckets**. The reason is that single slot spans are often handled by a different code path, and that distinction is made purely based on slot size, for simplicity and efficiency.

- 大小大於 4 partition pages 的 slot 對應到的 slot span 被稱作 single slot span，因為此 slot span 只會有一個 slot
- 但是同時又分類為 small bucket



PartitionAlloc handles **normal buckets** by **reserving (not committing)** 2MiB super pages. Each super page is split into **partition pages**. The first and the last partition page are permanently **inaccessible and serve as guard pages**, with the exception of **one system page** in the middle of the first partition page that holds **metadata** (**32B** struct per partition page).

- super page 的開頭與結尾的 partition page 稱作 guard pages，不能存取
- 而下個 system page 為 metadata page
  - object 為 32 bytes，用來 maintain 每個 partition page



As allocation requests arrive, there is eventually a need to allocate a **new slot span**. Address space for such a slot span is carved out from the last super page.

If not enough space, a **new super page is allocated**. Due to varying sizes of slot span, this may lead to leaving space unused (we **never go back to fill previous super pages**), which is fine because this memory is **merely reserved**, which is far less precious than committed memory. Note also that address space **reserved for a slot span is never released**, even if the slot span isn't used for a long time.

All slots in a newly allocated slot span are free, i.e. **available for allocation**.



All free slots within a slot span are chained into a **singly-linked free-list**, by writing the *next* pointer **at the beginning of each slot**, and **the head of the list is written in the metadata struct**.

- free slot 用 single linked-list 接起來，而 head 存放於 metadata



However, writing a pointer in each free slot of a newly allocated span would require **committing and faulting in physical pages upfront**, which would be unacceptable. (還沒被使用就要 page fault) Therefore, PartitionAlloc has a concept of **provisioning slots**. Only **provisioned slots are chained into the freelist**. Once provisioned slots in a span are depleted (耗盡), then another page worth of slots is provisioned (note, a slot that crosses a page boundary only gets provisioned with slots of the **next page**). See `PartitionBucket::ProvisionMoreSlotsAndAllocOne()` for more details.

Freelist pointers are stored at **the beginning of each free slot**. As such, they are the only **metadata** that is inline, i.e. stored among the objects



Slot Span States - A slot span can be in any of 4 states:

- **Full**. A full span has no free slots.
- **Empty**. An empty span has no allocated slots, only free slots.
- **Active**. An active span is anything in between the above two.
- **Decommitted**. A **decommitted span** is a special case of an **empty span**, where **all pages are decommitted from memory**



PartitionAlloc prioritizes getting an available slot from an **active span**, over an empty one, in hope that the latter can be soon transitioned into a **decommitted state**, thus **releasing memory**. There is no mechanism, however, to prioritize selection of a slot span based on **the number of already allocated slots**. (看 slot span 內有多少已經分配的 slot 決定要給哪個 slot span)

An empty span becomes **decommitted** either when there are **too many empty spans (FIFO)**, or when `PartitionRoot::PurgeMemory()` gets invoked **periodically** (or in **low memory pressure conditions**)

An allocation can be satisfied from a decommitted span if there are **no active or empty spans** available. The slot provisioning mechanism kicks back in, committing the pages gradually as needed, and the span becomes active. (There is currently no other way to **unprovision slots than decommitting the entire span**).

As mentioned above, a bucket is **a collection of slot spans containing slots of the same size**. In fact, each bucket has 3 linked-lists, chaining **active**, **empty** and **decommitted** spans (see `PartitionBucket::*_slot_spans_head`)

- bucket 擁有三個 linked-list，分別串起 active、empty 以及 decommited 的 slow spans



There is no need for a full span list. The lists are updated **lazily**. An empty, decommitted or full span may stay on the **active list** for some time, until `PartitionBucket::SetNewActiveSlotSpan()` encounters it. A decommitted span may stay on the **empty list** for some time, until `PartitionBucket<thread_safe>::SlowPathAlloc()` encounters it. However, the inaccuracy can't happen in the other direction, i.e. an active span can only be on the active list, and an empty span can only be on the active or empty list.



### Architecture

- super page - 2 MiB
  - super page is split into partition pages
  - 一次跟 system 要的大小
- partition page consists of exactly **4 system pages** - 16 KiB
  - 而在 ParitionAlloc 都是用 partition page 作為單位
  - Each partition holds multiple **buckets**
- A **bucket** is a series of regions in a partition that contains **similar-sized objects**, e.g. one bucket holds sizes (240, 256], another (256, 288], and so on
  - **8 buckets** between each power of two
  - slot size 跟 bucket 綁在一起，像是每個 allocation 落在 bucket (240; 256] 會滿足被分配 a slot of size 256
- **slot span** 存放相同大小的 slot，並且 slot span 的大小是 multiple of a partition page
- A slot is an **indivisible** allocation unit
- 大於 4 partition pages 的請求會被分配一個 single slot span，因為每個 slot span 都恰好包含一個 slot
- 小於 4 partition pages 的請求也有可能會產生包含一個 slot 的 slot span，但是仍被分配為 small bucket
  - 最多 4 partition pages 的分配被稱作 **small buckets**
  - **slot spans** are always between **1 and 4 partition pages in size**

所以是每次請求時會先看請求大小會是幾個 partition page，並且會檢查是否有存放對應大小 slot 的 slot span，如果有並且還有 freed slot 就直接回傳，其他情況就分配新的 slot span，而這個新的 slot span 會被 bucket maintain，之後從中拿 slot 回傳。



Bare in mind that the chromium codebase does not always just use `malloc()`. Some examples:

- Large parts of the **renderer (Blink)** use two **home-brewed allocators**, **PartitionAlloc** and BlinkGC (Oilpan).
- Some subsystems, such as the **V8 JavaScript engine**, handle memory management autonomously (自主地).
- Various parts of the codebase use abstractions such as `SharedMemory` or `DiscardableMemory` which, similarly to the above, have their own page-level memory management.



所以 chromium 主要分成三種記憶體處理相關的機制：

- 在 blink (render engine) 負責記憶體管理的 **PartitionAlloc**
- 在 blink 負責 GC 的 **Oilpan**
- v8 (javascript engine) 自己的記憶體管理



The allocator target defines at **compile-time** the **platform-specific** choice of the allocator and **extra-hooks** which services calls to **malloc/new**. The relevant build-time flags involved are **use_allocator and use_allocator_shim**.

Linux Desktop / CrOS use_allocator: `tcmalloc`, a forked copy of tcmalloc which resides in third_party/tcmalloc/chromium

- Setting use_allocator: none causes the build to fall back to the system (Glibc) symbols.

**Overview of the unified allocator shim** The allocator shim consists of three stages:

```
+-------------------------+    +-----------------------+    +----------------+
|     malloc & friends    | -> |       shim layer      | -> |   Routing to   |
|    symbols definition   |    |     implementation    |    |    allocator   |
+-------------------------+    +-----------------------+    +----------------+
| - libc symbols (malloc, |    | - Security checks     |    | - tcmalloc     |
|   calloc, free, ...)    |    | - Chain of dispatchers|    | - glibc        |
| - C++ symbols (operator |    |   that can intercept  |    | - Android      |
|   new, delete, ...)     |    |   and override        |    |   bionic       |
| - glibc weak symbols    |    |   allocations         |    | - WinHeap      |
|   (__libc_malloc, ...)  |    +-----------------------+    +----------------+
+-------------------------+
```


`PartitionAlloc` is **Blink‘s default memory allocator**. PartitionAlloc is highly optimized for performance and security requirements in Blink. All Blink objects that don’t need a GC or discardable memory should be allocated by PartitionAlloc (instead of malloc). The following objects are allocated by PartitionAlloc:

- Objects that have a `USING_FAST_MALLOC` macro.
- Nodes (which will be moved to Oilpan in the near future)
- LayoutObjects
- Strings, Vectors, HashTables, ArrayBuffers and other primitive containers.

The implementation is in `wtf/Partition*`

renderer (Blink) 大部分都是用 chromium 單獨設計的 PartitionAlloc 和 BlinkGC (Oilpan)，像 V8 這樣比較獨立的子系統使用自己的內存管理機制，還有部分模塊會使用抽象化的內存管理模塊如 ShareMemory 或者 DiscardMemory，和上面的內存管理器類似，他們也有自己的頁面級內存管理器

tcmalloc vs. PartitionAlloc ([src](https://source.chromium.org/chromium/chromium/src/+/master:base/allocator/allocator.gni;bpv=0;bpt=0)):

```cpp
# Copyright 2019 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import("//build/config/chromecast_build.gni")
import("//build/config/sanitizers/sanitizers.gni")

# Sanitizers replace the allocator, don't use our own.
_is_using_sanitizers = is_asan || is_hwasan || is_lsan || is_tsan || is_msan

# - Component build support is disabled on all platforms. It is known to cause
#   issues on some (e.g. Windows with shims, Android with non-universal symbol
#   wrapping), and has not been validated on others.
# - Windows: debug CRT is not compatible, see below.
# - Chromecast on Android: causes issues with crash reporting, see b/178423326.
_disable_partition_alloc =
    is_component_build || (is_win && is_debug) || (is_android && is_chromecast)
_is_partition_alloc_platform = is_android || is_win || is_linux || is_chromeos

# The debug CRT on Windows has some debug features that are incompatible with
# the shim. NaCl in particular does seem to link some binaries statically
# against the debug CRT with "is_nacl=false".
if ((is_linux || is_chromeos || is_android || is_apple ||
     (is_win && !is_component_build && !is_debug)) && !_is_using_sanitizers) {
  _default_use_allocator_shim = true
} else {
  _default_use_allocator_shim = false
}

if (_default_use_allocator_shim && _is_partition_alloc_platform &&
    !_disable_partition_alloc) {
  _default_allocator = "partition"
} else if (is_android || is_apple || _is_using_sanitizers || is_win ||
           is_fuchsia || ((is_linux || is_chromeos) && target_cpu == "arm64") ||
           (is_cast_audio_only && target_cpu == "arm")) {
  # Temporarily disable tcmalloc on arm64 linux to get rid of compilation
  # errors.
  _default_allocator = "none"
} else {
  _default_allocator = "tcmalloc"
}

```

Linux 當中 `malloc()` 以及 `free()` 會被替換成 tcmalloc，或者當 `use_allocator: none` 會使用原本的 `malloc()`

On Linux/CrOS: the **allocator symbols** are defined as **exported global symbols** in `allocator_shim_override_libc_symbols.h` ([src](https://chromium.googlesource.com/chromium/src/base/+/refs/heads/main/allocator/allocator_shim_override_libc_symbols.h)) (for malloc, free and friends) and in `allocator_shim_override_cpp_symbols.h` (for operator new, operator delete and friends).

This enables proper **interposition of malloc symbols** referenced by the main executable and any third party libraries. Symbol resolution on Linux is a **breadth first search** (BFS) that starts from the **root link unit**, that is the executable (see EXECUTABLE AND LINKABLE FORMAT (ELF) - Portable Formats Specification). Additionally, when `tcmalloc` is the default allocator, some extra glibc symbols are also defined in `allocator_shim_override_glibc_weak_symbols.h`, for subtle reasons explained in that file.

---

### Blink

Blink is a rendering engine of the web platform. Roughly speaking, Blink implements everything that renders content inside a browser tab:

- Implement the specs of the web platform (e.g., HTML standard), including **DOM, CSS and Web IDL**
- Embed **V8** and run JavaScript
- Request resources from the underlying network stack
- Build **DOM trees**
- Calculate style and layout
- Embed Chrome Compositor and draw graphics



How many renderer processes are created? For security reasons, it is important to **isolate memory address regions between cross-site documents** (this is called **Site Isolation**). Conceptually each renderer process should be dedicated to at most one site. Realistically, however, it's sometimes **too heavy** to limit each renderer process to a single site when users **open too many tabs** or the **device does not have enough RAM**. Then a renderer process may be shared by multiple iframes or tabs loaded from different sites. This means that **iframes** in one tab may be hosted by different renderer processes and that iframes in **different tabs** may be hosted by the same renderer process. There is no 1:1 mapping between renderer processes, iframes and tabs.

- 同 tab 的 iframe 可能會同時被不同的 render 共用
- 不同 tab 的 iframes 可能會被相同的 render 共用
- no 1:1



Given that a renderer process **runs in a sandbox**, Blink needs to ask the **browser** process to dispatch system calls (e.g., file access, play audio) and access user profile data (e.g., cookie, passwords). This browser-renderer process communication is realized by **Mojo**. (Note: In the past we were using **Chromium IPC** and a bunch of places are still using it. However, it's deprecated and uses **Mojo** under the hood.) On the Chromium side, **Servicification** is ongoing and abstracting the browser process as a set of "**service**"s. From the Blink perspective, Blink can just **use Mojo to interact with the services and the browser process**.

How many threads are created in a renderer process?

- Blink has **one main thread**, **N worker threads** and **a couple of internal threads.**
- Almost all important things happen on the main thread. All JavaScript (except workers), **DOM, CSS, style and layout calculations** run on the main thread. Blink is highly optimized to maximize the performance of the main thread, assuming the mostly single-threaded architecture.
- multiple worker threads to run **Web Workers, ServiceWorker and Worklets**
- **Blink and V8** may create a couple of internal threads to handle **webaudio, database, GC** etc.
- PostTask APIs instead of Shared memory programming to communicate with other thread

`WTF` is a "**Blink-specific base**" library and located at `platform/wtf/`. We are trying to unify **coding primitives** between **Chromium** and **Blink** as much as possible, so WTF should **be small**. This library is needed because there are a number of types, containers and macros that really need to be optimized for Blink's workload and **Oilpan (Blink GC)**. If types are defined in WTF, Blink has to **use the WTF types** instead of types defined in //base or std libraries. The most popular ones are **vectors, hashsets, hashmaps and strings**. Blink should use `WTF::Vector`, `WTF::HashSet`, `WTF::HashMap`, `WTF::String` and `WTF::AtomicString` instead of `std::vector`, `std::*set`, `std::*map` and `std::string`.

allocate an object on PartitionAlloc's heap by using `USING_FAST_MALLOC()`:

```cpp
class SomeObject {
  USING_FAST_MALLOC(SomeObject);
  static std::unique_ptr<SomeObject> Create() {
    return std::make_unique<SomeObject>();  // Allocated on PartitionAlloc's heap.
  }
};
```

- The lifetime of objects allocated by `PartitionAlloc` should be managed by `scoped_refptr<>` or `std::unique_ptr<>`. It is strongly discouraged to manage the lifetime manually. Manual delete is **banned** in Blink

You can allocate an object on Oilpan's heap by using `GarbageCollected`:

```cpp
class SomeObject : public GarbageCollected<SomeObject> {
  static SomeObject* Create() {
    return new SomeObject;  // Allocated on Oilpan's heap.
  }
};
```



### StarScan: Heap scanning use-after-free prevention

C++ and other languages that rely on explicit memory management using `malloc()` and `free()` are prone to memory corruptions and the resulting **security issues**. The fundamental idea behind these **heap scanning algorithms** is to intercept an underlying allocator and delay releasing of memory until the corresponding memory block is provably unreachable from application code.

The basic ingredients for such algorithms are:

1. *Quarantine*: When an object is deemed unused with a `free()` call, it is put into **quarantine** instead of being returned to the allocator. The object is not actually freed by the underlying allocator and cannot be used for future allocation requests until **it is found that no pointers are pointing to the given memory block**.
   - 會先放入暫存區 (Quarantine)，直到確定沒有被 reference 才會被釋放
2. *Scan*: When the quarantine reaches a certain **quarantine limit** (e.g. based on memory size of quarantine list entries), the quarantine scan is triggered. The scan iterates over the **application memory** and **checks if references are pointing to quarantined memory**. If objects in the quarantine are still referenced then they are kept in quarantine, if **not they are flagged to be released**.
   - Quarantine 沒有空間時會 trigger quarantine scan，檢查是否有 memory reference 到 quarantine 的記憶體，沒有的話就釋放
3. *Sweep*: All objects that **are flagged to be released** are actually **returned to the underlying memory allocator**.



***Probabilistic conservative scan (PCScan)*** (`pcscan.{h,cc}`) is one particular kind of heap scanning algorithm implemented on top of [PartitionAlloc](https://source.chromium.org/chromium/chromium/src/+/master:base/allocator/partition_allocator/PartitionAlloc.md#) with the following properties:

- Memory blocks are scanned conservatively for pointers.
- Scanning and sweeping are generally performed on a **separate thread** to maximize application performance.
- **Lazy safe points** prohibit certain operations from modifying the memory graph and provide convenient entry points for scanning the stack.

PCScan is currently considered **experimental** - please do not use it in production code just yet. It can be enabled in the following configurations via `--enable-features` on builds that use PartitionAlloc as the [main allocator](https://source.chromium.org/chromium/chromium/src/+/master:base/allocator/README.md#):

- `PartitionAllocPCScan`: All processes and all supporting partitions enable PCScan.
- `PartitionAllocPCScanBrowserOnly`: Enables PCScan in the browser process for the default malloc partition.



---

### fast-properties

JavaScript objects mostly behave like **dictionaries**, with **string keys** and **arbitrary objects** as values

- `["aaa": <object>]`
- the different properties **behave mostly the same**, independent of whether they are **integer indexed** or not

**Elements** (index 為數字) and **properties** (index 為 string) are stored in two separate data structures which makes adding and accessing properties or elements more efficient for different usage patterns

The **HiddenClass** stores information about the shape of an object, and among other things, a mapping from property names to indices into the properties

sometimes use a **dictionary** for the properties instead of a **simple array**



- **Array-indexed properties** are stored in a separate **elements** store.
- **Named properties** are stored in the **properties** store.
- Elements and properties can either be **arrays or dictionaries**.
- **Each** JavaScript object has a **HiddenClass** associated that keeps information about the object shape



HiddenClasses serve as an **identifier** for the **shape of an object** (又稱作 Map) and as such a very important ingredient for V8's optimizing compiler and **inline caches**. The optimizing compiler for instance can directly **inline property accesses** if it can ensure a compatible objects structure through the HiddenClass

In terms of properties, the most important information is the **third bit field**, which stores the number of properties, and **a pointer to the descriptor array**

the same named properties in the same order — share the **same HiddenClass**

In the background V8 creates a **transition tree** that **links the HiddenClasses together**. V8 knows which HiddenClass to take when you add, for instance, the property "a" to an empty object. This transition tree makes sure **you end up with the same final HiddenClass** if you add the **same properties in the same order** (用 back pointer 串起 ?)

if we create a new object that gets a different property added, V8 creates a **separate branch** for the new HiddenClasses



- Objects with the **same structure** (same properties in the same order) have the **same HiddenClass**
- By default every new named property added causes a **new HiddenClass to be created**
- Adding array-indexed properties does **not create new HiddenClasses**



While JavaScript objects behave more or less like simple dictionaries from the outside, V8 tries to **avoid dictionaries** because they hamper certain optimizations such as **inline caches** which we will explain in a separate post.



In-object vs. normal properties

- V8 supports so-called **in-object properties** which are **stored directly on the object themselves**
- These are the **fastest properties** available in V8 as they are accessible **without any indirection**
  - 最快

- The number of in-object properties is predetermined by the **initial size of the object**
- If more properties get added than there is space in the object, they are stored **in the properties store** (多的就放到另外一個 space). The properties store adds **one level of indirection** but can be grown independently.



Fast vs. slow properties

- The next important distinction is between **fast and slow properties**
- Typically we define the properties stored in the **linear properties store as "fast"**
  - Fast properties are simply accessed **by index** in the properties store
- To get from the name of the property to the actual position in the properties store, we have to consult the descriptor array on the **HiddenClass**, as we've **outlined** before



However, if many properties get added and deleted from an object, it can generate a lot of time and memory overhead to **maintain the descriptor array** and **HiddenClasses**

- slow properties - An object with slow properties has a **self-contained dictionary as a properties** store

All the properties meta information is **no longer** stored in the **descriptor array on the HiddenClass** but directly in the **properties dictionary** (不放在 hiddenclass 了)

- Hence, properties can be added and removed **without updating the HiddenClass**
- Since **inline caches don’t work with dictionary properties**, the latter, are typically slower than fast properties.
  - dictionary property 不能在 inline cache 的機制中使用




**summary**

- There are three different **named property types**: in-object, fast and slow/ dictionary
  - **In-object properties** are stored directly on the **object itself** and **provide the fastest access**
    - 直接在 object 內，空間有限但最快
  - **Fast properties** live in the **properties** store, all the meta information is stored in the **descriptor array** on the HiddenClass
    - 為 linear property，另外一個 space，meta 都存在 hiddenclass 的 descriptor array
  - **Slow properties** live in a **self-contained properties dictionary**, meta information is **no longer shared** through the HiddenClass
    - 將 metadata 與 property value 都存在一個 dictionary 當中
    - 在 hiddenclass 的某處存著 slow properties ptr (or buffer ?)
- **Slow properties** allow for efficient property removal and addition but are **slower to access than the other two types**
  - slow properties 在 delete / add properties 時會比其他兩種更有效率，但是更慢




element type 有許多種，可以參考：https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/elements-kind.h;l=1?q=elements-kind.h&sq=&ss=chromium

Packed or Holey Elements

- The first major distinction V8 makes is whether **the elements backing store** is **packed** or has **holes** in it. You get holes in a backing store if you **delete an indexed element**, or for instance, **you don't define it**

if a property is not present on the receiver we have to **keep on looking on the prototype chain**.

- Given that elements are **self-contained**, e.g. we don't store information about present indexed properties on the HiddenClass, we need a **special value**, called **the_hole**, to **mark properties that are not present**
- This is crucial for the performance of Array functions. If we know that there are **no holes**, i.e. the elements **store is packed**, we can perform **local operations** without expensive lookups on the prototype chain



Fast or Dictionary Elements

- The second major distinction made on elements is whether they are **fast or dictionary-mode**

- Fast elements are simple **VM-internal arrays** where the **property index** maps to the **index in the elements store**

- However, this simple representation is rather wasteful for very **large sparse/holey arrays** where only **few entries are occupied**

  - In this case we used a **dictionary-based representation** to save memory at the cost of slightly slower access, e.g.

    ```js
    const sparseArray = [];
    sparseArray[9999] = 'foo'; // Creates an array with dictionary elements.
    ```



**Smi and Double Elements**

- For fast elements there is another important distinction made in V8

- For instance if you only store integers in an `Array`, a common use-case, the GC does not have to look at the array, as integers are directly encoded as so called **small integers (Smis)** in place

- Another special case are Arrays that **only contain doubles**. Unlike Smis, floating point numbers are usually represented as **full objects occupying several words**

  - However, V8 stores **raw doubles** for **pure double arrays** to avoid memory and performance overhead

    ```js
    const a1 = [1,   2, 3];  // Smi Packed
    const a2 = [1,    , 3];  // Smi Holey, a2[1] reads from the prototype
    const b1 = [1.1, 2, 3];  // Double Packed
    const b2 = [1.1,  , 3];  // Double Holey, b2[1] reads from the prototype
    ```

**Special Elements**

- With the information so far we covered 7 out of the 20 different element kinds
- For simplicity we excluded 9 element kinds for TypedArrays, two more for String wrappers and last but not least, two more special element kinds for arguments objects.

**The ElementsAccessor**

- As you can imagine we are not exactly keen on writing Array functions 20 times in C++, once for every elements kind
- That's where some C++ magic comes into play. Instead of implementing Array functions over and over again, we built the **ElementsAccessor** where we mostly have to implement only simple functions that access elements from the **backing store**
- The ElementsAccessor relies on **CRTP** to create specialized versions of each Array function. So if you call something like slice on an array, V8 internally calls **a builtin written in C+**+ and dispatches through the **ElementsAccessor** to the specialized version of the function



- There are **fast and dictionary-mode** indexed properties and elements
- Fast properties can be **packed** or they can contain **holes** which indicate that an indexed property has been deleted
- Elements are **specialized** on their content to speed up Array functions and reduce GC overhead.



JS object 使用方式像是 dictionaries 的模式：

```js
a = {}
a.hello = 'world';
a.owo = function () { return 0x1234; }
```

而根據 key 為 **integer** 或是 **string** 有不同的名稱：

- integer - 稱作 **element**
- string - 稱作 **property**

不過 element 與 property 都有可能會以 dict 或是 array 的方式儲存，像是 property 有時會以 **simple array** 的方式儲存。而每個 object 都會有一個 **Hidden Class** (又稱作 Map) 描述 object 的結構 (shape)。

- 但 v8 會盡量避免用 dict 的方式儲存，因為 inline cache 與等等情況下不能 support



v8 內部的 **inline caches** 會使用到 hidden class 做 function 的加速，而 hidden class 是以 transition tree 的方式存在，當新增 property 時，會建立新的 hidden class，並將 back pointer 指回舊的 hidden class

- 但是這邊 property 就是以 string 為 index 的 element，如果以數字為 index 就不會建立新的 hidden class



v8 內部有使用 in-object property，是直接儲存在 object 內部，而存取這些 property 是最快的，因為不需要透過額外的 indirection (**fastest properties**)，不過 in-object 的大小在初始化 object 大小時就確定了

- 就是會先用 **in-object property**，沒有空間才會去用 **property store**



使用 **linear property store** 的話被稱作 **fast property**，因為 property 可以用 **index** 來存取，並且 property 還要去 hidden class 的 descriptor 找 property 對到的 key 的名字 (稱作 outline property (?))



- slow property 會有 **self-contained dictionary** 作為 properties store，代表 property meta 直接存在這個 properties dictionary 而非 descriptor array (in hidden class)，因此更新 property 時不需要更新 hidden class
- 這邊呼應 inline cache 無法 support dict 的情況，因此才被稱作 slow property



統整一下， **named property types** 一共有三種： in-object, fast and slow/ dictionary

- **In-object properties** - 直接存在 object 內，空間有限但最快
- **Fast properties** - 存在於 linear property store，metadata 放在在 hiddenclass 的 descriptor array
- **Slow properties** - property 有 self-contained properties dictionary，並且 metadata 存在 property store 當中
  - slow 在對 update / add / remove 資料時很有效率，但在 call function 時無法用 inline，比其他兩個慢



---

### V8 isolates, contexts, worlds and frames

> 從 [doc](https://chromium.googlesource.com/chromium/src/+/refs/heads/main/third_party/blink/renderer/bindings/core/v8/V8BindingDesign.md#A-relationship-between-isolates_contexts_worlds-and-frames) 上整理



### isolate

- An isolate is a concept of an instance in **V8**
- In **Blink**, isolates and threads are in 1:1 relationship
  - One isolate is associated with the **main thread**
  - One isolate is associated with one **worker thread**
    - An exception is a compositor worker where one isolate is **shared by multiple compositor workers**
  - main 跟 worker thread 都一定會有一個 isolate 空間，但 compositor worker (render 相關的 thread) 會共用一個 isolate



### Context

- A context is a concept of a global variable scope in V8
- Roughly speaking, one **window object** corresponds to one **context**
  - 一個 window object 對應到一個 context
  - For example, `<iframe>` has a window object different from a window object of its parent frame. So the context of the `<iframe>` is different from the context of the parent frame
  - Since these contexts create their **own global variable scopes, global variables and prototype chains** of the `<iframe>` are isolated from the ones of the parent frame
    - parent frame 跟 iframe 產生的 child frame 各別使用自己的 context
    - context 有自己的 global 資料，不與其他 isolate 共用
- Each frame has a window object. Each window object has a context. Each context has its own global variable scope and prototype chains



### Entered context and current context

A relationship between isolates and contexts

- One isolate has to execute JavaScripts in multiple frames, each of which has its own context. This means that the context associated with the isolate changes over time
- In other words, the relationship between isolates and contexts is 1:N over the lifetime of the isolate
  - 因為 isolate 要執行不同的 frame 的 JS，而每個 frame 又有自己的 context，因此基本上 isolate 與 context 為 1:N
- entered / current / debugger context
  - The entered context is a context from which the current JavaScript execution **was started**
  - The current context is a context of the JavaScript function that is **currently running**
  - If a debugger is active, the debugger context may be inserted to the context stack

### World

- A world is a concept to **sandbox DOM wrappers** among content scripts of Chrome extensions
- There are three kinds of worlds
  - a main world - a world where a **normal JavaScript downloaded from the web is executed**
  - an isolated world - a world where a **content script of a Chrome extension is executed**
    - main thread 的 isolate 有一個 main world 與 N 個 isolated worlds
  - a worker world
    - worker thread 的 isolate 只有一個 worker world
- 在同個 isolate 底下的 worlds 共享 C++ DOM objects
  - but each world has its own DOM wrappers. That way the worlds in one isolate can **operate on the same C++ DOM object** without sharing any DOM wrapper among the worlds.
- each world has its own context. This means that each world has its own **global variable scope and prototype chains**



As a result of the sandboxing, the worlds in one isolate **cannot share any DOM wrappers or contexts** but can share underlying C++ DOM objects

- The fact that no DOM wrappers or contexts are shared means that no JavaScript objects are shared among the worlds
  - JS 的 object 是不能被 share 的
- That way we guarantee the security model that Chrome extensions doesn't share any JavaScript objects while sharing the underlying C++ DOM objects. This sandbox allows the Chrome extensions to **run untrusted JavaScripts on a shared DOM structure**

(Note: An isolated world is a concept of **V8 binding**, whereas an isolate and a context are a concept of V8. V8 does not know what isolated worlds are in an isolate.)



**In summary** 

- an isolate of the main thread consists of **1 main world** and **N isolated worlds**
- An isolate of a worker thread consists of 1 worker world and 0 isolated world
- All worlds in one isolate **share the underlying C++ DOM objects**, but each world has **its own DOM wrappers**
- Each world has **its own context** and thus has **its own global variable scope and prototype chains**



### A relationship between isolates, contexts, worlds and frames

- As a requirement of the **DOM side**, one HTML page has N frames
  - Each frame has its own context.
- As a requirement of the **JavaScript side**, one isolate has M worlds
  - Each world has its own context.

As a result, when we execute the main thread where N frames and M worlds are involved, there exists N * M contexts. In other words, one context is created for each pair of (frame, world)

The main thread can have **only one current context at one time**, but the main thread can have the N * M contexts over its lifetime

- For example, when the main thread is operating on a frame X using a JavaScript in a world Y, the current context is set to a context for the pair of (X, Y). The current context of the main thread changes over its lifetime
- On the other hand, a worker thread has 0 frame and 1 world. Thus a worker thread has only 1 context. The current context of the worker thread **never changes**.



---

#### V8 APIs

There are a lot of **V8 APIs** defined in `/v8/include/v8.h`. Since V8 APIs are **low-level** and hard to use correctly, platform/bindings/ provides a bunch of **helper classes** that **wrap V8 APIs**. You should consider using the helper classes as much as possible. If your code has to use V8 APIs heavily, the files should be put in bindings/{core,modules}.

V8 uses **handles** to point to V8 objects. The most common handle is `v8::Local<>`, which is used to **point to V8 objects** from a machine stack. `v8::Local<>` must be used after allocating `v8::HandleScope` on the machine stack. `v8::Local<>` should not be used outside the machine stack:

```cpp
void function() {
  v8::HandleScope scope;
  v8::Local<v8::Object> object = ...;  // This is correct.
}

class SomeObject : public GarbageCollected<SomeObject> {
  v8::Local<v8::Object> object_;  // This is wrong.
};
```

If you want to point to V8 objects from outside the machine stack, you need to use wrapper tracing. However, you have to be really careful not to create a reference cycle with it. In general V8 APIs are hard to use.



**V8 wrappers**
Each **C++ DOM object** (e.g., **Node**) has its corresponding **V8 wrapper**. Precisely speaking, each **C++ DOM object** has its corresponding V8 wrapper per world.

V8 wrappers have **strong references** to their corresponding **C++ DOM objects**. However, the C++ DOM objects have only **weak references** to the V8 wrappers. So if you want to keep V8 wrappers alive for a certain period of time, you have to do that **explicitly**. Otherwise, V8 wrappers will be **prematurely collected** and **JS properties on the V8 wrappers will be lost**...

```cpp
div = document.getElementbyId("div");
child = div.firstChild;
child.foo = "bar";
child = null;
gc();  // If we don't do anything, the V8 wrapper of |firstChild| is collected by the GC.
assert(div.firstChild.foo === "bar");  //...and this will fail.
```



### V8 string

v8 的 string 有以下幾種表達方式：

- **SeqString**
  - 在 V8 heap 内使用 (array-like) 連續空間來儲存 string
  - 儲存格式分為 **OneByte**、**TwoByte **(Unicode)
- **ConsString(first, second)**
  - 在字串 concat 時，用 tree 來儲存 concat 後的 string
  - 最小 ConsString 長度為 `kMinLength` = 13，小於的話會直接 copy
  - 大於 13 會直接建立 tree structure
- **SliceString(parent, offset)**
  - 在字串切割時，用 **offset** and **[length]** 表示父字串 (parent) 的一部分
  - SliceString 最小長度也是 `kMinLength` = 13 
  - 在 SliceString 中被切割掉的字串**不會被** V8 GC 回收
- **ThinString(actual)**
  - 直接引用另一个字串 object (actual)
  - 多數情況下與 **ConsString(actual, empty_string)** 等價
  - 需要開 `--thin_strings`
- **ExternalString**
  - 在 V8 heap 外的字串
  - 儲存格式分為 **OneByte**、**TwoByte **(Unicode)



`ConsString()` 用 tree 來提升 concat 的效能，但是 operation 會比較複雜，實際上字串的生命週期可以分成二：

- 構造期 - 使用 `ConsString` 提升多次 concat 的性能
- 使用期 (access to read) - 使用 SeqString 降低 string 存取的複雜度

如果使用字串相關的操作 (如 `charAt()`)，v8 會假設之後可能還會對該 string 有更多類似的操作，因此字串會由構造期進入使用期，V8 把多層的 ConsString copy (flatten) 成 SeqString 以降低後續處理的複雜度，此過程稱作 **FlattenString**。

- 可以用 `%FlattenString` 強制 flatten
- 而 implicit 的 flatten 包含：
  - 轉為 number (`parseInt()`, `Number`)
  - 讀取字串 (`s[0]` / `charCodeAt`)
  - regexp 
  - 其中 `Number` 的性能最好
- 不過頻繁的 flatten 會影響效能，因此應該要在最後輸出字串時在使用

> [UTF-8](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/UTF-8) 是一種對 Unicode 的可變長度字串的編碼。
> 字元範圍是 1 ~ 3 bytes，Unicode6.1 是 1 ~ 4 bytes

v8 對外會以 flag 的方式包裝此種透過 side effect 達到的優化來避免開發者的疑惑 (如 `HINT_MANY_WRITES_EXPECTED`)



常量字串 (`InternalizedString`)

- 在分配常量字串時會先計算 **Jenkins's one-at-a-time hash** 作為 key，在 string_table 中嘗試找出與 hash 相同的字串並比較內容是否相同 (`kMaxHashCalcLength` = 16383)
  - 相同 - 直接回傳
  - 不同 - 分配新的 (in old data space)
- 可以透過 `%InternalizeString(str)` 直接將某 string 轉為 internalized

```js
abc = "abc";
%DebugPrint(abc)
DebugPrint: 0x2a7308250525: [String] in OldSpace: #abc
0x2a73080402cd: [Map] in ReadOnlySpace
 - type: ONE_BYTE_INTERNALIZED_STRING_TYPE
 - instance size: variable
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 0
 - enum length: invalid
 - stable_map
 - back pointer: 0x2a730804030d <undefined>
 - prototype_validity cell: 0
 - instance descriptors (own) #0: 0x2a73080401b5 <DescriptorArray[0]>
 - prototype: 0x2a7308040171 <null>
 - constructor: 0x2a7308040171 <null>
 - dependent code: 0x2a73080401ed <Other heap object (WEAK_FIXED_ARRAY_TYPE)>
 - construction counter: 0

abcd = abc + "d"
%DebugPrint(abcd)
DebugPrint: 0x2a73080c5429: [String]: "abcd"
0x2a7308040551: [Map] in ReadOnlySpace
 - type: ONE_BYTE_STRING_TYPE
 - instance size: variable
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 0
 - enum length: invalid
 - stable_map
 - back pointer: 0x2a730804030d <undefined>
 - prototype_validity cell: 0
 - instance descriptors (own) #0: 0x2a73080401b5 <DescriptorArray[0]>
 - prototype: 0x2a7308040171 <null>
 - constructor: 0x2a7308040171 <null>
 - dependent code: 0x2a73080401ed <Other heap object (WEAK_FIXED_ARRAY_TYPE)>
 - construction counter: 0

%InternalizeString(abcd)
%DebugPrint(abcd)
DebugPrint: 0x2a73080c5429: [String]: >"abcd"
0x2a7308040691: [Map] in ReadOnlySpace
 - type: THIN_ONE_BYTE_STRING_TYPE
 - instance size: 16
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 0
 - enum length: invalid
 - stable_map
 - back pointer: 0x2a730804030d <undefined>
 - prototype_validity cell: 0
 - instance descriptors (own) #0: 0x2a73080401b5 <DescriptorArray[0]>
 - prototype: 0x2a7308040171 <null>
 - constructor: 0x2a7308040171 <null>
 - dependent code: 0x2a73080401ed <Other heap object (WEAK_FIXED_ARRAY_TYPE)>
 - construction counter: 0
```

- `%InternaliszeString()` 內部會呼叫 `v8::internal::Factory::InternalizeString`，不過 `%InternaliszeString()` 沒辦法在平時被呼叫

- 可以透過將 string 設為 object key 的 side effect 來 trigger

  ```js
  function internFunc(str) {
      var obj = {};
      obj[str] = true;
      return Object.keys(obj)[0];
  }
  ```

  - 先在 old data 分配一個 SeqString object，並將 `str` 內容 copy 進去
  - object 的 `instance_type` 會被 mark 成 `kInternalizedTag`，代表常量字串
  - 用 `ThinString<Map>` 替換原 object `str` 的 map，其中使用了新分配的 SeqString object
  - 根據 ThinString 的大小調整 heap 
    - 沒有 `ThinString` 就不能，因為常量字串 (new space) 與 非常量字串 (old space) 分配的位置不同，因此不能做 in-place internalization

- 當字串被設置為 object property name 時，會被嘗試改造成常量化版本



### Others

**proxy** in javascript

- Used to re-define basic operation

magic number

- 代表 hole / missing number



## 文章分析

### [谷歌V8引擎探秘：基础概念](https://blog.dingkewz.com/post/tech/google_v8_core_concepts_01/)

Handle，簡單的說，是對一個特定 JS 對象的 index。它指向此 JS 對象在 V8 所管理的 Heap 中的位置。需要注意的是，Handle 不存於 Heap 中，而是**存在於 stack 中**。只有一個 Handle 被釋放後，此 Handle 才會從 stack 中 pop 出。這就帶來一個問題，在執行特定操作時，我們可能需要**聲明很多 Handle**。如果要一個個手動釋放，未免太麻煩。為此，我們使用 **Handle Scope** 來集中釋放這些 Handle。

Handle Scope，形象的說是一個可以**包含很多 Handle 的工作區**。當這個工作區 Handle Scope 被移出 stack 時，其所包含的所有 Handle 都會被移出堆棧，並且被 GC 標註，從而在後續的垃圾回收過程快速的定位到這些可能需要被銷毀的Handle。

Handle Type：

- Local Handle
- Persistent Handle
- UniquePersistent Handle
- Eternal Handle



compressed pointer 從 V8 8.0 才有 (Chrome 80) - https://v8.dev/blog/v8-release-80

https://blog.infosectcbr.com.au/2020/02/pointer-compression-in-v8.html，內容還有講解 exploit 的部分

isolate memory region - upper 32 bits 不變只有 lower 32 bits 變

-  **isolate root** 為 upper 32 bits
-  compress / decompress pointer 的部分在 https://source.chromium.org/chromium/chromium/src/+/master:v8/src/common/ptr-compr-inl.h;drc=7fc1bf7f07dacab1be87c6fde304750df5b7d4cd;bpv=0;bpt=1;l=58

有 `addrof()` 跟 `fakeobj()` 後

- fake a `JSArray` and control the elements pointer to gain **arbitrary r/w** primitives (within the V8 heap)，因為只能控制 lower 32bits
- allocating an `ArrayBuffer` on the V8 heap and overwriting its `backing store` to an arbitrary 64-bit memory address
  - performing reads and writes with it using either a **TypedArray** or a **DataView** object will grant you an arbitrary r/w primitive within the entire 64-bit address space
  - 因為 `backing stores` of array buffers are allocated using **PartitionAlloc**
    - All **PartitionAlloc** allocations go on a **separate memory region that is not within the V8 heap**. This means that the backing store pointer needs to be stored as an **uncompressed 64-bit pointer**, since its upper 32 bits are not the same as the **isolate root** and thus *have* to be stored with the pointer.



---

### [Mojo “Style” Guide](https://chromium.googlesource.com/chromium/src/+/refs/heads/main/docs/security/mojo.md)

**Mojo** structs, interfaces, and methods should all have comments. Make sure the comments cover **the “how” and the “why”** of using an interface and its methods, and not just the **“what”**. Document preconditions, postconditions, and trust: if an interface is implemented **in the browser process** and **handles requests from the renderer process**, this should be mentioned in the comments.

Complex features should also have an external `README.md` that covers the **high-level flow** of information through interfaces and how they interact to implement the feature.

Policy should be controlled solely by the browser process. “Policy” can mean any number of things, such as sizes, addresses, permissions, URLs, origins, etc. In an ideal world:

1. **Unprivileged process** asks for a capability from the **privileged process** that owns the resource.
2. **Privileged process** applies policy to find **an implementation for the capability**.
3. **Unprivileged process** performs **operations on the capability**, constrained in scope.

The privileged process must own the capability lifecycle



繞過 sandbox 的方法

- 打 OS sandbox feature
- 打 IPC layer
- Logic bug



---

### [FEEDBACK IN V8](https://slides.com/ripsawridge/deck)

hidden classes:

- Objects have a "**hidden class**" (called a Map in V8)
- The Map is the **first pointer** in every object
- The Map describes the **layout in memory**
- Adding/removing **properties changes the Map**

**INLINE CACHES** TO MAINTAIN AND OBSERVE LAYOUT

- An Inline Cache (IC) is a **listening site** placed in your code
- We have them at **LOAD, STORE and CALL** locations
- It **caches the Map of objects** that **pass by in the Feedback Vector** for the function
- https://zh.wikipedia.org/wiki/%E5%86%85%E8%81%94%E7%BC%93%E5%AD%98

Every function has a **Feedback Vector**. It's just an array that **holds state for each IC**



---

### [Objects in v8](https://segmentfault.com/a/1190000039908658/en)

An isolate is an **independent copy of the V8 runtime**, including a **heap manager**, **a garbage collector**, etc. Only **one thread** may access **a given isolate at a time**, but **different threads** may access **different isolates simultaneously**.

- An isolate is **not sufficient** for running scripts, however. You also need a **global (root) object**

A context defines a **complete script execution environment** by designating an object in an **isolate's heap** as a global object. (isolate 即為使用 `%DebugPrint()` 時所印出的那些 object data 的位址)

- Therefore, not only can **many contexts "exist" in a given isolate**, but they can also **share any or all of their objects easily and safely**. That's because their objects actually **belong to the isolate** and are **protected by the isolate's exclusive lock**.

- object - `TaggedImpl`

  - https://github.com/nodejs/node/blob/2883c855e0105b51e5c8020d21458af109ffe3d4/deps/v8/src/objects/tagged-impl.h#L24
  - pointer tagging / pointer compression
  - compiler, memory allocation at runtime will ensure that the address is aligned according to the word length

- GC - 用 "Accurate GC, Precise GC" 而不是 "Conservative GC, Conservative GC"

  - 為了避免意外 release 不該 release 的 memory，**conservative GC** 會將所有看起來像 pointer 的 address 給 mark 成使用中 (active)，這樣就不會出現意外釋放記憶體的問題

- 儲存方式 - 可以想像 object 儲存：

  ```js
  type Object = Record<string, number>;
  const obj = { field1: 1 };
  ```

  - key-pair 的方式應該很直觀，不過 number 的原因是因為他同時能代表 primitive，也能當作 reference 儲存記憶體



JSObject 是由多個 class 所包裝起來

- `Object` -->  `HeapObject` --> `JSReceiver` --> `JSObject`
  - HeapObject --> kMapOffset
  - JSReceiver --> kPropertyOrHashOffset
  - JSObject --> kElementOffset

如 `%DebugPrint()` 等稱作 runtime function，被定義在 **runtime.h** 當中

runtime 時 v8 會選一個值作為 `expected_nof_properties`，當作 inobject attribute 的初始數字

在 JS 當中，`Class` 只是一個語法糖，實際上為 `FUNCTION_TYPE`

CreateObjectLiteral 跟 Create from class 得到的 object 有些差別，像是前者並不會保留額外多的  inobject properties 給 object，但是 create empty object literal 又會

- https://github.com/nodejs/node/blob/fb180ac1107c7f8e7dea9c973844dae93b2eda04/deps/v8/src/init/bootstrapper.cc#L720
- `kInitialGlobalObjectUnusedPropertiesCount` == 4



```js
const obj = {};
const cnt = 19;
for (let i = 0; i < cnt; i++) {
  obj["p" + i] = 1;
}
%DebugPrint(obj);
```



```
# 4
DebugPrint: 0x3de5e3537989: [JS_OBJECT_TYPE]
 #...
 - properties: 0x3de5de480b29 <FixedArray[0]> {

#19
DebugPrint: 0x3f0726bbde89: [JS_OBJECT_TYPE]
 #...
 - properties: 0x3f0726bbeb31 <PropertyArray[15]> {

# 20
DebugPrint: 0x1a98617377e1: [JS_OBJECT_TYPE]
 #...
 - properties: 0x1a9861738781 <NameDictionary[101]>
```



`%DebugPrint()` show **FixedArray** because when the fast type is not used, `propertiesOrHash_ptr` points to a **empty_fixed_array**



---

### [V8引擎JSObject结构解析和内存优化思路](https://zhuanlan.zhihu.com/p/55903492)

`FixedArray` 對應到 fast-properties

- 儲存除了 in-object 的 value (number / pointer)

`HashTable` 對應到 slow-properties

in-object properties 類似 fast-properties 但直接存在 object 當中

Map objecg 本身的 map 指向 metamap



flow

- in-object 在 instance 建立時就已經分配好大小
- 當 in-object 使用完畢，會接著用 PropertyArray (DescriptorArray 用來存 key name)
- 雖然 PropertyArray 會動態擴充，但用太多時會變成 dictionary 模式 (slow)
  - 不會有 in-object property，map descriptor len 為 0，意即直接存在 `NameDictionary` 中 (也就是 property back store)
  - slow property 用 hashtable 存，但是 Entry detail 會紀錄 element 的順序

什麼時候會轉換，用太多的定義為何？

- v8 當中有兩種 property 的定義方式
  - `a['b'] = 0` or `a.b = 0` - NamedStore
    - `PropertyArray` 的 element 數量大於 128 或全部 attribute 大於 1020
  - `a[b] = 0` - KeyedStore (dynamic)
    - `PropertyArray` 的 attribute 不能超過 inobject properties

fast mode memory 的使用來源

- descriptor array
- transition tree (backpointers)
  - 指向 parent map，如果沒 parent 就會指向 map constructor，發生幾次 transition 就有幾個 map
  - 每個 map 80 bytes
- inobject properties
- property array



object literal 就是用 `{}` 所建立的 instance



function `JSObject::MigrateSlowToFast` 將 `NameDictionary` 轉為 `FixedArray`

- 反之 `JSObject::MigrateFastToSlow` 則是將 `FixedArray` 變成  `NameDictionary`
- 不太懂為什麼 slow 能轉成 fast，不過文章說 object literal instance 的 attr 個數如果 `1021 > n >= 128`，會直接建 slow instance，之後再嘗試將其轉乘 fast instance，即 `MigrateSlowToFast`

function `Map::TooManyFastProperties` 會回傳是否達到 Fast 上限，之後會呼叫 `JSObject::MigrateFastToSlow` 來將 fast property 轉為 slow property

- source: https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/map-inl.h;l=180?q=TooManyFastProperties



---

### [奇技淫巧学 V8](https://zhuanlan.zhihu.com/p/28777722)

object property mode:

- Dictionary(Slow) Mode 也稱作 hash mode
- Stable(Fast) Mode

小的 instance 會是 fast mode，而當：

- 動態加太多 property
- `delete` property
  - `delete` **不是最後加上去**的 property（V8 >= 6.0）

可以用 Runtime call 來看：

```js
%HasFastProperties(obj);
%ToFastProperties(obj); // force
```

example:

```js
let obj = {'a': 1, 'b': 2};
%HasFastProperties(obj); // true

delete obj.a;
%HasFastProperties(obj); // false
// or
delete obj.b;
%HasFastProperties(obj); // true, 因為是最後
```

不過 `JSObject` 也是有可能會從 slow property 轉成 fast property，像是：

```js
function MagicFunc(obj) {
    function FakeConstructor() {
        this.a = 0;
    }
    FakeConstructor.prototype = obj;
    new FakeConstructor();
    new FakeConstructor();
};

var obj = {'a': 1, 'b': 2};
delete obj.a;
%HasFastProperties(obj); // false
MagicFunc(obj);
%HasFastProperties(obj); // true
```

properties / elements space 不足時會建立 (or copy) 一個更大的 `FixedArray`，而關於動態分配的情況以及 property 的轉變，可以參考下方：

```js
let obj = {};
%DebugPrint(obj);

DebugPrint: 0xdb2080c2a25: [JS_OBJECT_TYPE]
 - map: 0x0db2082802d9 <Map(HOLEY_ELEMENTS)> [FastProperties]
 - prototype: 0x0db208240629 <Object map = 0xdb2082801c1>
 - elements: 0x0db2080406e9 <FixedArray[0]> [HOLEY_ELEMENTS]
 - properties: 0x0db2080406e9 <FixedArray[0]> {}
0x0db2082802d9: [Map]
 - type: JS_OBJECT_TYPE
 - instance size: 28
 - inobject properties: 4
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 4
 - enum length: invalid
 - stable_map

obj.x = 0;
obj.y = 1;
obj.z = 2;

%DebugPrint(obj)
DebugPrint: 0xdb2080c2a25: [JS_OBJECT_TYPE]
 - map: 0x0db2082837d1 <Map(HOLEY_ELEMENTS)> [FastProperties]
 - prototype: 0x0db208240629 <Object map = 0xdb2082801c1>
 - elements: 0x0db2080406e9 <FixedArray[0]> [HOLEY_ELEMENTS]
 - properties: 0x0db2080406e9 <FixedArray[0]> {
    0xdb20824e9a5: [String] in OldSpace: #x: 0 (const data field 0)
    0xdb20824fbb5: [String] in OldSpace: #y: 1 (const data field 1)
    0xdb20824fce9: [String] in OldSpace: #z: 2 (const data field 2)
 }
0x0db2082837d1: [Map]
 - type: JS_OBJECT_TYPE
 - instance size: 28
 - inobject properties: 4
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 1
 - enum length: invalid
 - stable_map

obj[0] = 'a';
obj[1] = 'b';

%DebugPrint(obj)
DebugPrint: 0xdb2080c2a25: [JS_OBJECT_TYPE]
 - map: 0x0db2082837d1 <Map(HOLEY_ELEMENTS)> [FastProperties]
 - prototype: 0x0db208240629 <Object map = 0xdb2082801c1>
 - elements: 0x0db2080c456d <FixedArray[17]> [HOLEY_ELEMENTS]
 - properties: 0x0db2080406e9 <FixedArray[0]> {
    0xdb20824e9a5: [String] in OldSpace: #x: 0 (const data field 0)
    0xdb20824fbb5: [String] in OldSpace: #y: 1 (const data field 1)
    0xdb20824fce9: [String] in OldSpace: #z: 2 (const data field 2)
 }
 - elements: 0x0db2080c456d <FixedArray[17]> {
           0: 0x0db20808bf09 <String[1]: #a>
           1: 0x0db20808c1e5 <String[1]: #b>
        2-16: 0x0db208040385 <the_hole>
 }
0x0db2082837d1: [Map]
 - type: JS_OBJECT_TYPE
 - instance size: 28
 - inobject properties: 4
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 1
 - enum length: 3
 - stable_map

obj.a = 'a';
obj.b = 'b';
obj.c = 'c';

%DebugPrint(obj)
DebugPrint: 0xdb2080c2a25: [JS_OBJECT_TYPE]
 - map: 0x0db208283849 <Map(HOLEY_ELEMENTS)> [FastProperties]
 - prototype: 0x0db208240629 <Object map = 0xdb2082801c1>
 - elements: 0x0db2080c456d <FixedArray[17]> [HOLEY_ELEMENTS]
 - properties: 0x0db2080c4b51 <PropertyArray[3]> {
    0xdb20824e9a5: [String] in OldSpace: #x: 0 (const data field 0)
    0xdb20824fbb5: [String] in OldSpace: #y: 1 (const data field 1)
    0xdb20824fce9: [String] in OldSpace: #z: 2 (const data field 2)
    0xdb20808bf09: [String] in ReadOnlySpace: #a: 0x0db20808bf09 <String[1]: #a> (const data field 3)
    0xdb20808c1e5: [String] in ReadOnlySpace: #b: 0x0db20808c1e5 <String[1]: #b> (const data field 4) properties[0]
    0xdb208250671: [String] in OldSpace: #c: 0x0db208250671 <String[1]: #c> (const data field 5) properties[1]
 }
 - elements: 0x0db2080c456d <FixedArray[17]> {
           0: 0x0db20808bf09 <String[1]: #a>
           1: 0x0db20808c1e5 <String[1]: #b>
        2-16: 0x0db208040385 <the_hole>
 }
0x0db208283849: [Map]
 - type: JS_OBJECT_TYPE
 - instance size: 28
 - inobject properties: 4
 - elements kind: HOLEY_ELEMENTS
 - unused property fields: 1
 - enum length: invalid     
 - stable_map
```



`JSObject` 的 member 有：

- type：  instance 是一個 `JSObject`
- inobject properties： instance 的 in-object property 空間
- unused property fields： 沒有使用的 property 空間
- instance size： instance 在 heap 當中的大小
- constructor： instance 的 constructor
- prototype： instance 的 prototype
- stable[dictionary]： instance 目前的 property 狀態
  - stable_map： 快速模式
    - 用 map -> `instance_descriptors` -> `DescriptorArray` 當中的 name 來判斷 property **name**
    - 在 `FixedArray` 找對應到的 **value**
  - dictionary_map： 字典模式
    - 用 Jenkins hash function 存取 property

P.S. 在這時我發現因為 compress pointer 的關係，結構都不是這麼好看，因此可以去 chromium 看一下 class 的 source code 以及對應的欄位，這邊貼出 `JSObject` 的 source code 連結：

- https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-objects.h;l=305?q=JSObject&ss=chromium
- `JSObjec` 繼承 ` JSReceiver`
  - https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-objects.h;l=305
  - `v8::internal::JSObject*`
  - 不過看起來不像是用 `%DebugPrint()` 印出來的格式
- `JSReceiver` 繼承 `HeapObject`
  - https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/heap-object.h;drc=00a8ca06f8f356e7e25ad9eac59364d51884af30;l=27
- `HeapObject` 繼承 `Object`
  - https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/objects.h;drc=00a8ca06f8f356e7e25ad9eac59364d51884af30;l=272

gdb 斷點：

- `JSReceiver::initialize_properties` 
- `Factory::JSFunctionBuilder::BuildRaw`
  - https://source.chromium.org/chromium/chromium/src/+/main:v8/src/heap/factory.cc;l=3764



v8 的 isolate struct 為 `v8::internal::Isolate`，map struct 為 `v8::internal::Map`，還有 `v8::internal::Object` 等等。

`v8::internal::HeapObject` 的記憶體結構如下：

```
$7 = {
  <v8::internal::Object> = {
    <v8::internal::TaggedImpl<v8::internal::HeapObjectReferenceType::STRONG, unsigned long>> = {
      static kIsFull = true,
      static kCanBeWeak = false,
      ptr_ = 63638667061245 // 0x39e10824e7fd
    },
    members of v8::internal::Object:
    static kHeaderSize = 0
  }, <No data fields>}
```





---

### [V8 的記憶體管理機制](https://deepu.tech/memory-management-in-v8/)

JavaScript is single-threaded V8 also uses a single process per **JavaScript context**

- Heap Memory

  - 最大塊的記憶體

  - Garbage Collection(GC) 發生的地方，但只會在 Young and Old space 發生

  - **New Space** (又稱 **young** generation)

    - **new objects** live and most of these objects are **short-lived**
    - space is **small** and has two **semi-space**
    - managed by the “**Scavenger(Minor GC)**”
    - 大小可以用 `--min_semi_space_size` 以及 `--max_semi_space_size` 控制

  - **Old Space** (又稱作 **Old** generation)

    - objects that survived the “New space” for **two minor GC cycles** are moved to

      space is managed up by the **Major GC(Mark-Sweep & Mark-Compact)**

    - 可以用 `--initial_old_space_size` 與 `--max_old_space_size` 來控制大小

      - Old pointer space - Contains **survived objects** that **have pointers to other objects**
      - Old data space - Contains **objects** that just **contain data**(no pointer to other objects)
        - Strings, boxed numbers, and arrays of unboxed doubles are moved here after **surviving in “New space” for two minor GC cycles**

  - **Large object space**

    - This is where objects which are **larger than the size limits of other spaces live**
    - Each object gets its own **mmap'd** region of memory
    - Large objects are **never** moved by the garbage collector

  - **Code-space**

    - This is where the **Just In Time(JIT) compiler** (turbofan) stores **compiled code Blocks**
    - This is the only space with **executable memory** (although Codes may be allocated in “**Large object space**”, and those are executable, too)

  - **Cell space, property cell space, and map space**

    - These spaces contain **Cells, PropertyCells, and Maps**, respectively
    - Each of these spaces contains objects which are all the **same size** and has some constraints on what kind of objects they point to, which simplifies collection

  - Each of these spaces is composed of **a set of pages** (by mmap). Each page is **1MB** in size, except for **Large object space**

- **Stack**

  - This is the stack memory area and there is **one stack per V8 process**
  - This is where **static data** including **method/function frames**, **primitive values**, and **pointers to objects** are stored
  - 大小可以用 `--stack_size` 調整



**Functions** are just objects in JavaScript



V8 manages the heap memory by **garbage collection** (GC)

- Free those objects that are **no longer referenced from the Stack directly** or **indirectly**(via a reference in another object) to make space for new object creation
- **Orinoco** is the codename of the **V8 GC project** to make use of **parallel**, incremental and concurrent techniques for garbage collection, to free the main thread
  - Minor GC (Scavenger)
    - keeps the **young** or **new** generation space compact and clean
      - 只負責清理 young 的 GC
    - Objects are allocated in new-space, which is fairly small (**1 ~ 8 MB**, depending on behavior heuristics)
    - Allocation in “**new space**” is very cheap: there is an **allocation pointer** which we increment whenever we want to reserve space for a new object
      - allocation pointer 在要保留 space 時會增加，到結尾時 minor GC 會被 trigger，使用 Cheney’s algorithm 實作 GC，又被稱作 Scavenger
    - 兩個相同 size 的 semi-space： `to-space` and `from-space`
      - Most allocations are made in **from-space** 但除了一些特別的 object，如 executable Codes 一定會被 allocate 到 old-space
      - 所以當 from-space 滿的時候就會觸發，從 root 開始 traverse：
        - in-used / 被 in-used refenece - 丟到 to-space，並且更新 reference pointer
        - 全部 scan 完後，**to-space** 直接變成 **from-space**，不但同時減少 fragment，也把沒用到的 free 掉了
      - 但是結束後還是沒有空間該怎麼處理？ trigger **second minor GC**
        - alive object - First-time survivors 被丟到 to-space，第二次開始就會丟到 old space (因為長期 alive)
        - non-alive 直接在 from-space 被清掉
        - to-space 跟 from-space 交換
        - 新的被分配到 from-space
    - 大多數 ojbect 都是在 new space 待一下，馬上就被 Minor GC 清掉
  - Major GC
    - 清理 old generation space，在 old-space 沒有空間時被觸發
    - 大小為動態計算，並且 old-space 會被 minor GC 逐漸填滿
    - 使用 **Mark-Sweep-Compact algorithm** 而非 Scavenger，是因為 Scavenger 對小記憶體很有效，但是在大塊記憶體時會有大量的 overhead (如 copy data)
      - 使用 tri-color(white-grey-black) marking system
      - 分成三步驟：
        - **Marking**
          - First step, common for both algorithms, where the garbage collector 用來辨識哪些用哪些沒用
          - The objects in use or **reachable from GC roots(Stack pointers)** recursively are marked as **alive**
          - It’s technically a DFS of the heap which can be considered as a DG
        - **Sweeping**
          - The garbage collector traverses the heap and **makes note of the memory address of any object that is not marked alive**
          - This space is now marked as **free** in the **free list** and **can be used to store other objects**
        - **Compacting**
          - After sweeping, if required, all the survived objects will be **moved to be together**
          - This will **decrease fragmentation** and increase the performance of allocation of memory to newer object
          - compact by heuristic
      - 被稱作 stop-the-world GC，因為在清掃過程中可能會出現暫停 (pause)，不過 v8 有一些機制可以避免：
        - **Incremental GC**
          - GC is done in **multiple incremental steps** instead of one
        - **Concurrent marking**
          - Marking is done **concurrently** using **multiple helper threads** without affecting the main JavaScript thread
          - **Write barriers** are used to **keep track of new references between objects** that JavaScript creates while the **helpers are marking concurrently**
        - **Concurrent sweeping/compacting**
          - Sweeping and compacting are **done in helper threads concurrently** without affecting the main JavaScript thread
        - **Lazy sweeping**
          - Lazy sweeping involves **delaying the deletion of garbage** in pages until memory is required
    - 總結一下流程：
      - 假設多次 minor GC cycles 執行完畢，並且 old space 幾乎滿了，讓 V8 trigger “**Major GC**”
      - Major GC 從 stack pointers 開始 recursively 遍歷 object graph，並 mark 那些 used memory (alive) objects，留下的 objects 為 garbage (Orphans) in the old space
      - 上述使用多個 concurrent helper threads，並且每個 helper 都 follows a pointer (?)，不會影響到 main JS thread
      - When concurrent marking is done or if the memory limit is reached, the GC does a **mark finalization step** using the **main thread**
        - 會有 small pause time
      - Major GC now marks all orphan object’s memory as free using **concurrent sweep threads**
        - **Parallel compaction** 也會被 trigger，把相關連的 block 丟到相同 page，避免/減少 fragmentation
        - Pointers are updated during these steps (換到新的 address 之類的)



---

### unknown



```js
function point(x, y) {
    // will allocate this = {}
    this.x = x;
    this.y = y;
}

var p1 = new point(1, 2);
var p2 = new point('a', 'b');
```

- p1, p2 share 相同的 Map / DescriptorArray



JS 的：

```js
function getX(point) {
    return point.x;
}
```

可以看成 JS engine 當中的：

```js
function getX(point) {
    return Runtime_Load(point, "x");
}
```

1. 從 object 的 `<Map>` 中取得 `instance_descriptors`
2. `instance_descriptors` 遍歷得到 key 的位置 (在 object 内 or 在 properties 中)
3. 呼叫特定的方法讀取

pseudo code 為：

```js
function Runtime_Load(obj, key) {
    var desc = obj.map().instance_descriptors();
    var desc_number = -1;
    for (var i = 0; i < desc.length; i++) {
        if (desc.GetKey(i) === key) {
            desc_number = i;
            break;
        }
    }

    if (desc_number === -1) {
    	return undefined;
    }

    var detail = desc.GetDetails(desc_number);
    if (detail.is_inobject()) {
    	return obj.READ_FIELD(detail.offset());
    } else {
    	return obj.properties().get(detail.outobject_array_index());
    }
}
```

當這段程式碼被大量執行後，js engine 會發現每次都找同一個位置，如果能透過紀錄起來 (cache) 以及簡單的檢查，就能減少搜尋的時間，增加效能。簡化後的流程如下：

1. 檢查 object 的 `<Map>` 與之前 cache 的是否相同
2. 如相同，直接從 cache 的位置讀
3. 如不同，呼叫 `Runtime_Load`

pseudo code:

```js
function getX(point) {
    return LoadIC_x(point);
}
```

````js
function LoadIC_x(obj) {
  if (obj.map() === cache.map) { // 比較是否為同個 map
    if (cache.offset >= 0) {
      return obj.READ_FIELD(cache.offset);
    } else {
      return obj.properties().get(cache.index);
    }
  } else {
      return Runtime_LoadIC_Miss(obj, "x"); // 不是同個 map，不能直接用 cache
  }
}
````

```js
function Runtime_LoadIC_Miss(obj, key) {
    // … …
    cache = {map : obj.map()};
    if (detail.is_inobject()) {        
        cache.offset = detail.offset();
        // … …
    } else {
        cache.index = detail.outobject_array_index();
        // … …
    }
}
```

- 當 miss 時可以存起來

but will be defeated by:

```js
for (var i = 0; i < 10000; i++) {
    if (i % 2) {
        getX({x : 1});
    } else {
        getX({x : 1, y : 2});
    }
}
```

因此改動 `Runtime_LoadIC_Miss`，將 cache 由單一儲存改為 hash table mode，將遇到的 `<Map>` 及其 attr 存取位置全部cache 下来：

```js
function Runtime_LoadIC_Miss(obj, key) {
    // … …
    var cache = {map : obj.map()};
    if (detail.is_inobject()) {        
        cache.offset = detail.offset();
        caches.push(cache);
        // … …
    } else {
        cache.index = detail.outobject_array_index();
        caches.push(cache);
        // … …
    }
}
```

除此之外 `LoadIC_x` 也需做調整：

```js
function LoadIC_x(obj) {
    for (var i = 0; i < caches.length; i++ ) {
        if (obj.map() === caches[i].map) {
            if (caches[i].offset >= 0) {
                return obj.READ_FIELD(caches[i].offset); // object offset 即是
            } else {
                return obj.properties().get(caches[i].index); // 從 property 拿
            }
        }
    }
    return Runtime_LoadIC_Miss(obj, "x"); // miss
}
```

- 雖然命中率上升，但是效能也下降 (branch check)

P.S. point.x 可以稱作一個 **callsite**，把 x 稱為一條名為 x 的消息，而實際執行的 point (`{x : 1}` or `{x : 1, y : 2}`) 被為該 callsite 的 **receiver**。

JavaScript 中很多操作的過程複雜，但對特定的 call (callsite) 來說 receiver 的 `<Map>` 變化一般很小，因此 v8 用 inline cache (IC) 來 cache function call 的實作以優化執行過程：

```js
obj.x;                // LoadIC(x)
obj["x"];            // LoadIC(x)

obj.x = 1;           // StoreIC(x)
obj["x"] = 1;        // StoreIC(x)

var key = "_";
obj[key + "x"];      // KeyedLoadIC(x) 動態
obj[key + "x"] = 1;  // KeyedStoreIC(x)
```

根據 receiver type 的多寡以及種類，會呈現不同的狀態：

- uinitialized
- premonomorphic - 訊息不足
- monomorphic - type == 1
- polymorphic - type > 1, type <= 4
- megamorphic - type > 4
- `kMaxPolymorphicMapCount = 4`
- `kMaxKeyedPolymorphism = 4`

Profile-guided optimization (PGO) == profile-directed feedback (PDF) == feedback-directed optimization (FDO)，皆指 compiler 在 runtime 蒐集資訊來做 optimization



Runtime call `%ToFastProperties()` 是直接呼叫 `v8::internal::JSObject::MigrateSlowToFast`，而若無 runtime call 使用，也能透過 function 的 side effect 來達成Ｌ。當 `StoreIC` (`LoadIC`) 並非 unitialized 時，每次更新 IC 都會跑 `MakePrototypesFast` --> `MigrateSlowToFast`，將 dict mode 優化成 fast mode：

```js
function MagicFunc(obj) {
    function FakeConstructor() {
        this.x = 0; // StoreIC(x)
    }

    // copy <Map> 為 prototype，不與其他 object share
    FakeConstructor.prototype = obj;

    // StoreIC(x) state == UNINITIALIZED
    new FakeConstructor();
    // StoreIC(x) state == PREMONOMORPHIC

    new FakeConstructor();
    // StoreIC(x) state == MONOMORPHIC
    // implicitly call MakePrototypesFast，從 slow mode 轉為 fast mode
};
```



把某 object `FakeConstructor` 的 prototype 設為其他 object `b`，object `b` 的 `map` 會被 copy 一份，因此與 `a` 不在 share 同個 map (但是 map 的內容一樣)：

```js
let a = {x: 1};
let b = {x: 1};
%HaveSameMap(a, b); // true
var FakeConstructor = function () {};
FakeConstructor.prototype = b;
%HaveSameMap(a, b); // false，因為 b 變成 FakeConstructor 的 prototype
```

- `%HaveSameMap()` 可以看兩個 object 的 `JSObject<Map>` 是否相同



還有其他能夠透過 v8 side effect 來 trigger slowToFast，如：

```js
function MagicFunc_Alt(obj) {
    var fakeObj = {};
    function FakeLoad() {
        fakeObj.x; // LoadIC(x)，即使 x 不存在
    }

    // CopyAsPrototype
    fakeObj.__proto__ = obj;

    // LoadIC(x) state == UNINITIALIZED
    FakeLoad();
    // LoadIC(x) state == PREMONOMORPHIC
    FakeLoad();
    // LoadIC(x) state == MONOMORPHIC
    // implicitly call MakePrototypesFast, 從 slow mode 轉為 fast mode
}
```



現實中應該會常使用到 `delete` operation，但即使能透過這種方式轉換成 fast mode，轉換過程也是有**額外的 overhead**，並且這種靠 side effect 的方法不太可靠。

在 v8 >= 6.0，刪除的 property 滿足以下條件時不會轉換成 dictionary mode：

- object 為 JavaScript 常規(?) instance (?)
- property name 為常量化 string (不能為變數) or Symbol
- 刪除的 property 必須是最後被加到 object 的
- property 可以被刪
- backpointer 引用的 type 必须是 `<Map>` (?)
- 最後一次 Map Transition 只能由 object 新增 property 而觸發

因為是最後加進去的，所以可以做類似 undo 的行為



---

### [WebAssembly compilation pipeline](https://v8.dev/docs/wasm-compilation-pipeline)

**Liftoff**

- V8 first compiles a WebAssembly module with its baseline compiler, **Liftoff**
- Liftoff is a **one-pass compiler**, which means it iterates over the WebAssembly code once and emits machine code immediately for each WebAssembly instruction
- One-pass compilers excel at fast code generation, but can only apply **a small set of optimizations**
- Indeed, Liftoff can compile WebAssembly code very fast, 10s of megabytes per second. Once Liftoff compilation is finished, the compiled WebAssembly module is returned to JavaScript

Liftoff emits decently fast machine code in a very short period of time. However, because it emits code for each WebAssembly instruction independently, there is **very little room for optimizations**, like improving register allocations or common compiler optimizations like redundant load elimination, strength reduction, or function inlining

This is why, as soon as Liftoff compilation is finished, V8 immediately starts to "tier up" the module by **recompiling** all functions with **TurboFan**, the optimizing compiler in V8 for both **WebAssembly and JavaScript**

- TurboFan is a **multi-pass compiler**, which means that it builds multiple internal representations of the compiled code before emitting machine code. These additional internal representations allow **optimizations** and **better register allocations**, resulting in significantly faster code

TurboFan compiles the **WebAssembly module** function by function. As soon as one function finishes, it immediately **replaces the function** compiled by Liftoff

Any new calls to that function will then use the new, optimized code produced by TurboFan, not the Liftoff code. Note though that we don’t do **on-stack-replacement**. This means that if TurboFan finishes optimizing a function that was already invoked when only the Liftoff version was available, it will **finish its execution using the Liftoff version**



**Code caching**

- If the WebAssembly module was compiled with `WebAssembly.compileStreaming`, then the TurboFan-generated machine code will also **get cached**
- When the same WebAssembly module is fetched again from the same URL, the module is **not compiled but loaded from cache**
- More information about **code caching** is available in a separate blog post

**Debugging**

- As mentioned earlier, TurboFan applies optimizations, many of which involve **re-ordering code**, eliminating variables or even skipping whole sections of code
- This means that if you want to set a breakpoint at a specific instruction, it might not be clear where program execution should actually stop. In other words, TurboFan code is not well suited for debugging
- Therefore, when debugging is started by opening DevTools, all TurboFan code is replaced by Liftoff code again **("tiered down")**, as each WebAssembly instruction maps to exactly one section of machine code and all local and global variables are intact

**Profiling**

- To make things a bit more confusing, within DevTools all code will **get tiered up** (**recompiled with TurboFan**) again when the **Performance tab** is opened and the **"Record" button in clicked**. The "Record" button starts **performance profiling**. Profiling the Liftoff code would not be representative as it is only used while TurboFan isn’t finished and can be significantly slower than TurboFan’s output, which will be running for the vast majority of time



---

### [Orinoco: The new V8 Garbage Collector Peter Marshall](https://www.youtube.com/watch?v=Scxz6jVS4Ls&ab_channel=NearForm)

雖然 copy 昂貴，不過還是 copy 需要的而已

- nursery --> intermediate --> old space (generation) (通常會存在很久)

major GC (full mark-compact)

- scan 並 mark 所有 unreachable，並且放入 free list
- 還是會 compact，但是不會 compact 所有 page

Orinoco

- goal - "free the main thread"
  - help thread + main thread
  - concurrent - no pause time
    - marking
    - compact + update
    - sweep

https://v8.dev/blog/jank-busters

Escape analysis

- In compiler optimization, **escape analysis** is a method for determining the **dynamic scope of pointers** – where in the program a pointer can be accessed. It is related to pointer analysis and shape analysis.
- When a variable (or an object) is allocated in a subroutine, a pointer to the variable **can escape to other threads of execution**, or to **calling subroutines**. If an implementation uses **tail call optimization** (usually required for functional languages), objects may also be seen as escaping to called subroutines



尾呼叫 (tail call) 是指一個函數裡的最後一個動作是**返回一個函式的呼叫結果**的情形，即最後一步新呼叫的返回值直接被當前函式的返回結果，此時，該尾部呼叫位置被稱為尾位置

- 經過適當處理，**尾遞迴形式**的函式的執行效率可以被極大地最佳化
- 尾呼叫原則上都可以通過**簡化函式呼叫棧**的結構而獲得效能最佳化（稱為「**尾呼叫消除**」），但是最佳化尾呼叫是否方便可行取決於執行環境對此類最佳化的支援程度如何



---

### [How JavaScript works: memory management + how to handle 4 common memory leaks](https://blog.sessionstack.com/how-javascript-works-memory-management-how-to-handle-4-common-memory-leaks-3f28b94cfbec)

The main concept garbage collection algorithms rely on is the one of reference

- An object is considered “garbage collectible” if there are zero references pointing to it
- There is a limitation when it comes to **cycles** (a --> b , b --> a)

Mark-and-sweep algorithm

- In order to decide **whether an object is needed**, this algorithm determines whether the object is reachable
- inspects all roots and their children and marks them as active
  - Anything that a root cannot reach will be marked as garbage

what's memory leak?

- memory leaks are pieces of memory that the application **have used in the past** but is **not needed any longer** but has **not yet been return back** to the OS or the pool of free memory

four types of common JavaScript leaks

- Global var

  ```js
  function foo(arg) {
      bar = "some text";
  }
  // equal to
  function foo(arg) {
      window.bar = "some text";
  }
  ```

  - please use `var` or add `use strict` in the beginning of js

- Timers or callbacks that are forgotten

- Closures

  - **once a scope for closures is created for closures in the same parent scope, the scope is shared**

- Out of DOM references



---

### [JavaScript 引擎基础：Shapes 和 Inline Caches](https://zhuanlan.zhihu.com/p/38202123)



---

### [逆工程 JS 对象 (一): 浅谈 V8 对象布局](https://zhuanlan.zhihu.com/p/103750829)



---

### [Compressed pointers in V8](https://docs.google.com/document/d/10qh2-b4C5OtSg-xLwyZpEI5ZihVBPtn1xwKBbQC26yI/edit?fbclid=IwAR0p3oIoh9w3Jv9AmrNSLoobahSdoKDg8g8N7cxyKMlkNgzuEtW5WPID_zM#heading=h.l3c73n8yohth)



use “root” register as a V8 heap base register we have to ensure that all the values previously accessible via the root register would be still accessible via the V8 heap base register

- store there a pointer to the `v8::internal::Isolate` object
  - 存一個指向 `v8::internal::Isolate` object 的 pointer



四種方式

- base points to the beginning, page aligned
- base points to the beginning, 4Gbyte-aligned
- base points to the middle, 4Gbyte-aligned (preferred one)
- base points to the beginning, 4Gbyte-aligned, smi-corrupting



V8 uses a **heap snapshot** to reduce the time it takes to create a new isolate (and possibly context)

- At build time, a **snapshot of the heap** is created **using the serializer**, and **stored in a raw data file** that is distributed with the V8 binary called `snapshot_blob.bin`
- When a **new isolate is created**, the snapshot file is **loaded into memory and deserialized to create an identical heap state**, saving time on startup

Complicated unboxed doubles support

- It would be hard to support **unboxed double fields** because of object field shifting when changing representation from Smi to Double or from Double to Tagged. However, it is **still doable**
- Or we may decide to use a completely different approach for unboxing doubles which will also work for 32-bit architectures: we may consider using `FixedDoubleArray` as a **separate backing** for all the double properties
- This would be a bit **less efficient** but more **GC friendly** approach than we have right now



---

### [An internship on laziness: lazy unlinking of deoptimized functions](https://v8.dev/blog/lazy-unlinking)

Each function also has a **trampoline to the interpreter** and will **keep a pointer to this trampoline** in its `SharedFunctionInfo (SFI)`

This trampoline will be used whenever V8 needs to **go back to unoptimized code**. Thus, upon deoptimization, triggered by passing an argument of a **different type** (bailout)

If the function f1 is deoptimized, we need to make sure that the invalidated code will **not be executed again by invoking f2** (相同的 pointer 都必須要更新)

Thus, upon deoptimization, V8 used to **iterate over all the optimized JavaScript functions**, and would **unlink those that pointed to the code object being deoptimized**. This iteration in applications with many optimized JavaScript functions became a **performance bottleneck**

### Lazy unlinking

- When such functions are invoked, V8 checks **whether they have been deoptimized**, unlinks them and then continues with their **lazy compilation**
- 不在 GC 時回收而是只設 mark_for_deoptimization bit，並在下次呼叫此 function 時才做 **unlink it** and **jump to lazy compiled code**
  - If these functions are never invoked again, then they will **never be unlinked** and the deoptimized code objects **will not be collected**
  - However, given that during deoptimization, we invalidate all the **embedded fields of the code object**, we only **keep that code object alive**

`CompileLazyDeoptimizedCode` 的另一方面要做的就是，從 JavaScript 函數中 unlink code field，並將其設置為 Trampoline 到 Interpreter 



---

### [Deoptimization in V8](https://docs.google.com/presentation/d/1Z6oCocRASCfTqGq1GCo1jbULDGS-w-nzxkbVF7Up0u0/edit#slide=id.p)

這篇講 deoptimize

If a dynamic parameters check fails the deoptimizer deoptimizes the code:

- **Discards** the optimized code
- Builds the **interpreter frame** from the optimized stack/registers
- Jumps to the **interpreter**



deoptimizer 的行為：

- Reads out **current stack frame** and **HW register** file into a buffer
- Builds **interpreter frame(s)** from the (optimized) stack frame and registers
  - Using information **emitted by the compiler** (aka `DeoptimizationInputData`)
  - The information contains:
    - **Shared function info** and **bytecode offset** to resume at
    - Locations of **parameters in hardware registers/stack slots**
    - Locations of **interpreter registers** (in hardware registers/stack slots)
    - … for each **inlined frame**
- Materializes objects that have been compiled away by **escape analysis**
- Jumps to the **interpreter dispatch**



---

### [INVERTING YOUR ASSUMPTIONS: A GUIDE TO JIT COMPARISONS](https://www.zerodayinitiative.com/blog/2018/4/12/inverting-your-assumptions-a-guide-to-jit-comparisons)



---

### [理解 V8 的字节码「译」](https://zhuanlan.zhihu.com/p/28590489)



---

### [Understanding V8’s Bytecode](https://medium.com/dailyjs/understanding-v8s-bytecode-317d46c94775)

V8 的 interpreter 是用 **Ignition**

- Ignition is a register machine with an accumulator register
- can think of V8's bytecodes as **small building blocks**
- Each bytecode specifies its **inputs and outputs** **as register operands**. Ignition uses registers **r0, r1, r2, ...** and an **accumulator register**



bytecode begin with `Lda` or `Sta`

- `a` == **a**ccumulator
- Ld == Load
- St == Store

e.g.

```js
function incrementX(obj) {
  return 1 + obj.x;
}
incrementX({x: 42});  // V8’s compiler is lazy, if you don’t run a function, it won’t interpret it.
```

- 沒被執行前只會做 lazy parsing

產生出來的 bytecode 為：

```
[generated bytecode for function: incrementX]
Parameter count 2
Register count 1
Frame size 8
   20 E> 0x2cc946d9fa32 @    0 : a5                StackCheck
   30 S> 0x2cc946d9fa33 @    1 : 0c 01             LdaSmi [1]
         0x2cc946d9fa35 @    3 : 26 fb             Star r0
   45 E> 0x2cc946d9fa37 @    5 : 28 02 00 01       LdaNamedProperty a0, [0], [1]
   39 E> 0x2cc946d9fa3b @    9 : 34 fb 00          Add r0, [0]
   47 S> 0x2cc946d9fa3e @   12 : a9                Return
   
   
0x2cc946d9f9e1: [FixedArray] in OldSpace
 - map: 0x077c35c80801 <Map>
 - length: 1
           0: 0x2cc946d9f249 <String[#1]: x>
```

- `LdaSmi [1]` - loads the constant value `1` in the accumulator (acc)
- `Star r0` - stores the value that is currently in the accumulator (acc) into **r0**
- `LdaNamedProperty a0, [0], [1]` - loads a named property of **a0** into the accumulator
  - **aX** refers to the **i**-th argument of `incrementX()`
  - look up a named property on `a0`, and name is determined by the constant `0`
    - In the example  `0` maps `x`, so this bytecode loads `obj.x`
  - 4 is an **index of the so-called feedback vector** of the function `incrementX()`
    - feedback vector contains **runtime information** that is used for **performance optimizations**
- `Add r0, [6]` - adds r0 to the accumulator, resulting in `43`
  - `6` is another **index of the feedback vector**
- `Return` - returns the value in the accumulator



---

### [Slack tracking in V8](https://v8.dev/blog/slack-tracking)

Slack tracking is a way to give new objects an initial size that is **larger than what they may actually use**, so they can have new properties added quickly. And then, after some period of time, to **magically return that unused space to the system**

initial map 中會存放一個 counter (value 為 7)，當 constructor 被呼叫時就會 -1，到 0 的時候會將沒有使用到的空間收回 (透過 `JSFunction::CalculateExpectedNofProperties()`)，而多出來的空間會用 **filler** 去填滿，不過統計沒有使用到的空間應該只有 inobject property

在 optimize function 時，如果使用到的 map 在往後可能會因為 counter 到 0 做優化而造成 map struct 的改變 (updating of instance size)，可能會有 side effect 的疑慮，因此也會順便 slack tracking，因為正常來說被 object 被當作參數使用數萬次應該已經做 slack tracking 了

- 之後新增的 property 會被放到 backing store



---

### [What's up with monomorphism?](https://mrale.ph/blog/2015/01/11/whats-up-with-monomorphism.html)

monomorphism(1) / polymorhism(2+) / megamorphic (4+)

- megamorphic - "give up tracking them"
  - V8 **megamorphic ICs** can still continue to cache things but instead of doing it locally they will put what they want to cache into a **global hashtable**
  - hashtable has **a fixed size** and entries are **simply overwritten on collisions**



Monomorphic cache says **I’ve only seen type A**
Polymorphic cache of degree N says **I’ve only seen A1, …, AN**
Megamorphic cache says **I’ve seen a lot of things**



---

### [V8 internals for JavaScript developers](https://slidr.io/mathiasbynens/v8-internals-for-javascript-developers#1)

Element

- PACKED_SMI_ELEMENTS - `[1, 2, 3]`
  - then `push(4.56)`
- PACKED_DOUBLE_ELEMENTS
  - then `push('x')`
- PACKED_ELEMENTS
  - then `arr[9] = 1`
- HOLEY_ELEMENTS (SMI / DOUBLE / ELEMENTS)
  - 要檢查 undefined (hole)，所以很慢
- lattice system

- 一共有 21 種 element type
  - https://source.chromium.org/chromium/v8/v8.git/+/ec37390b2ba2b4051f46f153a8cc179ed4656f5d:src/elements-kind.h;l=14

NaN, Infinity, -0 由 double 的方式表示

[video](https://www.youtube.com/watch?v=m9cTaYI95Zc)
